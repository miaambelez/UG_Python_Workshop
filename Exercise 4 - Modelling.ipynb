{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary: if running on Colab, get the data from GitHub\n",
    "try:\n",
    "  import google.colab\n",
    "  print(\"Downloading data from GitHub...\")\n",
    "  !wget -nc -P'Data' https://github.com/miaambelez/UG_Python_Workshop/raw/main/Data/Exercise4.csv\n",
    "  print(\"...done!\")\n",
    "except:\n",
    "  print(\"Running locally, data should be already on path!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will implement a classification model to predict which patients will get caries in the coming year and which not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('Data/Exercise4.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df[['DATE_OF_BIRTH_YEAR', 'DATE_OF_BIRTH_MONTH',\n",
    "       'DATE_OF_BIRTH_DAY', 'AGE', 'N_PERIODONTAL', 'N_FILLING',\n",
    "       'N_ORAL_HYGIENE', 'N_CHECKS', 'N_YEARS', 'PR_DENTIST', 'DPSI',\n",
    "       'N_FAMILY', 'DIABETES', 'SMOKER']]\n",
    "y = df['Y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate train and test data sets\n",
    "A first step is to split the data between training and test (out of sample) data. Use scikit learn to split the data, where 80% of the rows will form the training data and the rest will be test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and train the model\n",
    "Now that we have a dedicated train and test dataset, we can train a classification model on the data. Use the next block to train a logistic regression model and get the predictions of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# your code here\n",
    "\n",
    "# Train the model\n",
    "# your code here\n",
    "\n",
    "# Get the predictions\n",
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the model performance\n",
    "With the trained model, we can evaluate how the model performs on out of sample observations. To do this, we can make use of the accuracy. What is the accuracy of your trained model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = # your code here\n",
    "print(f'The accuracy of the Logistic Regression is {accuracy:.2f}') \n",
    "# This print statement is a nice way of including variables in the print statement by using {}.\n",
    "# Furthermore, to format floats, we can use the .2f which tells Python to format on 2 decimals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is a very straightforward metric for classification, but not always the best option. Especially when there is an uneven distributions in the classes. Can you think of a reason why? As an alternative, we can use the recall score. Calculate the recall score for your trained logistic regression model. Print the recall rounded up to three decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "recall = # your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrain the model\n",
    "The scikit learn LogisticRegression classifier takes no required arguments when initializing. However, it definitely takes optional arguments. This includes amongst others a penalty parameter, a regularization parameter, or the solver that will be used. Always check the documentation to find out which arguments a function takes. Train a new logistic regression model that takes class imbalance in the target variable into account. How big is the difference in accuracy, if any? And in the recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the relation between the variables and the target variable. How can you interpret them and are they as expected? Hint: one could evaluate the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All performance metrics for classification models can be constructed from the so called confusion matrix, which is an overview of the amount of True Positives (TP), False Positives (FP), False Negatives (FN) and True Negative (TN). Use a scikit learn method to get the confusion matrix for the trained model. Hint: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you also compute the accuracy from the confusion matrix result, using Python code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of other models to use? How can you efficiently test them? Do you have an idea of how to explain the outcome of a certain model? What are advantages and disadvantages in the models you used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
